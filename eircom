Analysing the consumer opinions based on the subjective tweets and most talked issues.
#I was working with a pre-existing sentimental analysis available on the Kaggle webiste.
# This is based on my personal interest based on the product based organisation
#Register API
#print the Auth. key
api_key <- '*******'
api_secret <- '*******'
access_token <- '************'
acccess_token_secret <- '*********'

#Loading the library
install.packages("twitteR")
library('twitteR')
setup_twitter_oauth(api_key, api_secret, access_token, acccess_token_secret)
install.packages("SchedulerR")

account <- "eircare"
account
account.timeline <- userTimeline(account, n=2000, includeRts = TRUE)
eirdf <- twListToDF(account.timeline)


write.csv(eirdf, file = 'eir.csv', row.names = F)
getwd()

#Read file
eircare <- read.csv(file.choose(), header = T)
str(eircare)

#Build Corpus
install.packages("tm")
library(tm)
corpus <- iconv(eircare$text, to = "")
corpus <- Corpus(VectorSource(corpus))
inspect(corpus[1:5])

#Data Cleaning
corpus <- tm_map(corpus, tolower)
inspect(corpus[1:5])

#Removing Special characters
corpus <- tm_map(corpus, removePunctuation)
inspect(corpus[1:5])

corpus <- tm_map(corpus, removeNumbers)
inspect(corpus[1:5])

#Removing common words
cleanset <- tm_map(corpus, removeWords, stopwords('english'))
inspect(cleanset[1:5])

#Removing URL
removeURL <- function(x) gsub('http[[:alnum:]]*', '', x)
cleanset <- tm_map(cleanset, content_transformer(removeURL))
inspect(cleanset[1:5])

#removing the white spaces
cleanset <- tm_map(cleanset, stripWhitespace)
inspect(cleanset[1:5])

#Term document matrix(converting into stuctured format)
TermDocumentMatrix(cleanset) -> tdm
tdm
tdm <- as.matrix(tdm)
tdm[1:10, 1:20]

#Bar plot
#frequent words
frequent_words <- rowSums(tdm)
frequent_words
subset(frequent_words, frequent_words>90) -> frequent_words
barplot(frequent_words, 
        las = 2,
        col = rainbow(20))

#Word Cloud
install.packages("wordcloud")
library(wordcloud)
w <- sort(rowSums(tdm), decreasing = TRUE)
set.seed(123)
wordcloud(words = names(w), freq = w)
wordcloud(words = names(w), freq = w, 
          max.words = 200, 
          random.order = FALSE, 
          min.freq = 75,
          colors = brewer.pal(8, 'Dark2'),
          scale = c(5, 0.70), rot.per = 0.5)

#Another similar library
install.packages("wordcloud2")
library(wordcloud2)
w <- data.frame(names(w), w)
w
colnames(w) <- c('word', 'freq')
wordcloud2(w[1:50, ], size = 0.3, shape = 'star')
letterCloud(w, word = "A", size = 2)

#Sentimental Analysis
install.packages("syuzhet")
install.packages("lubridate")
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
library(syuzhet)
library(lubridate)



tweets <- iconv(eircare$text, to = '')  
s <-  get_nrc_sentiment(tweets)
head(s)  
tweets[2]  

#Barplot on Sentimental Scores
barplot(colSums(s), 
        las = 2,
        col = rainbow(30),
        ylab = 'Count', 
        main = 'Sentiment Scores for EIRCARE Tweets from Last one Month')


